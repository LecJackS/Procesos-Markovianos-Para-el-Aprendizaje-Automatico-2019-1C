{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NxgP4gIN5eF"
   },
   "source": [
    "**Recycling robot example** (from Sutton, page 42)\n",
    "References:\n",
    "  - Gym documentation: https://gym.openai.com/\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQ-0sEtFFcTM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym.envs.toy_text import discrete\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3dzvy9s6aX3"
   },
   "outputs": [],
   "source": [
    "# TODO: Describir coloquialmente el modelo de sutton\n",
    "# TODO: Explicar lo básico de GYM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPaZiYtu6aX6"
   },
   "source": [
    "# Considere el modelo del robot de reciclaje descríto en Sutton Example 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/example3.2-1.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/example3.2-2.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U96qJdswGBFr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "states = [\"high\", \"low\"]\n",
    "actions = [\"wait\", \"search\", \"recharge\"]\n",
    "\n",
    "P = {}\n",
    "\n",
    "P[0] = {}\n",
    "P[1] = {}\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "r_wait = 0.5\n",
    "r_search = 2.0\n",
    "\n",
    "# definimos un ambiente discreto con las transiciones según el gráfico\n",
    "def generar_ambiente(alpha=alpha, beta=beta, r_wait=r_wait, r_search=r_wait):\n",
    "    P[0][0] = [(1.0, 0, r_wait, False)]\n",
    "    P[0][1] = [(alpha, 0, r_search, False),\n",
    "               (1-alpha, 1, r_search, False)]\n",
    "    P[0][2] = [(1,0,0,False)]\n",
    "\n",
    "    P[1][0] = [(1.0, 1, r_wait, False)]\n",
    "    P[1][1] = [(beta, 1, r_search, False), \n",
    "               (1-beta, 0, -3.0, False)]\n",
    "    P[1][2] = [(1.0, 0, 0.0, False)]\n",
    "    env = discrete.DiscreteEnv(2, 3, P, [0.0, 1.0])\n",
    "    return(env)\n",
    "env = generar_ambiente()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvcF7--Z6aX8"
   },
   "source": [
    "# Implemente la estrategia random para veinte episodios. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoNiKgvOIC3n"
   },
   "source": [
    "Definir una acción aleatoria y ver que reward produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs\tDone\tReward\tC.Reward\tAction\n",
      "0 \t False \t 0.0 \t 0.000 \t\t 2\n",
      "0 \t False \t 0 \t 0.000 \t\t 2\n",
      "0 \t False \t 0 \t 0.000 \t\t 2\n",
      "0 \t False \t 0 \t 0.000 \t\t 2\n",
      "0 \t False \t 0.5 \t 0.100 \t\t 0\n",
      "0 \t False \t 0.5 \t 0.167 \t\t 0\n",
      "0 \t False \t 0.5 \t 0.214 \t\t 0\n",
      "0 \t False \t 0 \t 0.188 \t\t 2\n",
      "0 \t False \t 0.5 \t 0.222 \t\t 1\n",
      "0 \t False \t 0.5 \t 0.250 \t\t 1\n",
      "0 \t False \t 0.5 \t 0.273 \t\t 0\n",
      "0 \t False \t 0 \t 0.250 \t\t 2\n",
      "0 \t False \t 0.5 \t 0.269 \t\t 0\n",
      "0 \t False \t 0 \t 0.250 \t\t 2\n",
      "0 \t False \t 0 \t 0.233 \t\t 2\n",
      "0 \t False \t 0 \t 0.219 \t\t 2\n",
      "0 \t False \t 0 \t 0.206 \t\t 2\n",
      "0 \t False \t 0 \t 0.194 \t\t 2\n",
      "0 \t False \t 0.5 \t 0.211 \t\t 1\n",
      "0 \t False \t 0.5 \t 0.225 \t\t 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Obs\\tDone\\tReward\\tC.Reward\\tAction\")\n",
    "verbose=True\n",
    "history = []\n",
    "rewardAcum = 0\n",
    "for i in range(20):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "    rewardAcum += reward\n",
    "    elemHist = np.array([i, reward, rewardAcum])\n",
    "    history.append(elemHist)\n",
    "    if verbose:\n",
    "        print(observation,\"\\t\", done,\"\\t\", reward, \"\\t\", \"%.3f\" % (rewardAcum/(i+1)), \"\\t\\t\", action)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9kpyAEk6aYB"
   },
   "source": [
    "# Grafique la recompensa acumulada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [2. , 0. , 0. ],\n",
       "       [3. , 0. , 0. ],\n",
       "       [4. , 0.5, 0.5],\n",
       "       [5. , 0.5, 1. ]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to numpy\n",
    "history = np.array(history)\n",
    "history[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0. , 0.5, 0.5])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so I can do this\n",
    "history[0:6, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2854417ce80>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.xlabel(\"time step\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.xticks(np.arange(0,len(history),1))\n",
    "plt.plot(history[:,0], history[:,2], 'ro', label='Reward acumulado')\n",
    "plt.plot(history[:,0], history[:,1], 'b.', label='Reward instantáneo')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qC0PJOkV6aYH"
   },
   "source": [
    "# Calcule de forma teórica V, la value function optima para cada estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en cada estado, quiero calcular la value function optima;\n",
    "# uso ecuacion de bellman, tomando el reward instantaneo y\n",
    "# estimando futuros posibles rewards a partir de las acciones.\n",
    "\n",
    "print(\"Obs\\tDone\\tReward\\tC.Reward\\tAction\")\n",
    "verbose=True\n",
    "gamma=0.9\n",
    "history = []\n",
    "rewardAcum = 0\n",
    "for i in range(20):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "    # bellman eq\n",
    "    V = reward + gamma * ()\n",
    "    rewardAcum += reward\n",
    "    elemHist = np.array([i, reward, rewardAcum])\n",
    "    history.append(elemHist)\n",
    "    if verbose:\n",
    "        print(observation,\"\\t\", done,\"\\t\", reward, \"\\t\", \"%.3f\" % (rewardAcum/(i+1)), \"\\t\\t\", action)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x: actual state\n",
    "#y's: next states\n",
    "V(x) = reward + gamma (sum_y( p(y|a,x) * V(y) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRz0uMX1LbXz"
   },
   "source": [
    "# Implemente el algoritmo de iteración de valor (Value iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVuBLOrWL1ru"
   },
   "source": [
    "  Evaluate the optimal value function given a full description of the environment dynamics\n",
    "  \n",
    "  \n",
    "\n",
    "```\n",
    " Args:\n",
    "\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "  \n",
    "  Returns:\n",
    "        Vector of length env.nS representing the value function.\n",
    "```\n",
    "\n",
    "\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGWxWGNA6aYJ"
   },
   "source": [
    "# Implemente el algoritmo de policy iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9o3S2kaKQKX"
   },
   "source": [
    "Definir primero una funcion de evaluación de politica,\n",
    "\n",
    "```\n",
    "Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
    "    \n",
    "    Args:\n",
    "        policy: [S, A] shaped matrix representing the policy.\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "    \n",
    "    Returns:\n",
    "        Vector of length env.nS representing the value function.\n",
    "        \n",
    "```\n",
    "\n",
    "Despues una funcion de optimisacion de la politica:\n",
    "\n",
    "\n",
    "```\n",
    " Policy Improvement Algorithm. Iteratively evaluates and improves a policy\n",
    "    until an optimal policy is found.\n",
    "    \n",
    "    Args:\n",
    "        env: The OpenAI envrionment.\n",
    "        policy_eval_fn: Policy Evaluation function that takes 3 arguments:\n",
    "            policy, env, discount_factor.\n",
    "        discount_factor: gamma discount factor.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (policy, V). \n",
    "        policy is the optimal policy, a matrix of shape [S, A] where each state s\n",
    "        contains a valid probability distribution over actions.\n",
    "        V is the value function for the optimal policy.\n",
    "        \n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brOjUJvE6aYV"
   },
   "source": [
    "# Utilizando los 3 algoritmos, realice los experimentos para las siguientes configuraciones del ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVKvrm0t6aYV"
   },
   "outputs": [],
   "source": [
    "exp1 = generar_ambiente(alpha=0.9, beta=0.9, r_search=3, r_wait=2)\n",
    "exp2 = generar_ambiente(alpha=0.8, beta=0.5, r_search=3, r_wait=2)\n",
    "exp3 = generar_ambiente(alpha=0.5, beta=0.5, r_search=3, r_wait=2)\n",
    "exp4 = generar_ambiente(alpha=0.9, beta=0.6, r_search=1, r_wait=0.9)\n",
    "exp5 = generar_ambiente(alpha=0.9, beta=0.6, r_search=1, r_wait=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAT_YZq56aYY"
   },
   "source": [
    "# Utilizando el grafico de recompensa, compare las estrategias óptimas generadas con los experimentos anteriores contra la estrategia al azar."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP1 - (Sin solucion).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
