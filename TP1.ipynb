{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NxgP4gIN5eF"
   },
   "source": [
    "**Recycling robot example** (from Sutton, page 42)\n",
    "References:\n",
    "  - Gym documentation: https://gym.openai.com/\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQ-0sEtFFcTM"
   },
   "outputs": [],
   "source": [
    "from gym.envs.toy_text import discrete\n",
    "#from gym import spaces\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3dzvy9s6aX3"
   },
   "source": [
    "##### TODO: Describir coloquialmente el modelo de sutton\n",
    "Dos estados: high y low\n",
    "Tres acciones: search, wait, recharge\n",
    "\n",
    "##### TODO: Explicar lo básico de GYM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPaZiYtu6aX6"
   },
   "source": [
    "# Considere el modelo del robot de reciclaje descríto en Sutton Example 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/example3.2-1.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/example3.2-2.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U96qJdswGBFr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "states = [\"high\", \"low\"]\n",
    "actions = [\"wait\", \"search\", \"recharge\"]\n",
    "\n",
    "P = {}\n",
    "\n",
    "P[0] = {}\n",
    "P[1] = {}\n",
    "\n",
    "alpha = 0.8\n",
    "beta = 0.1\n",
    "r_wait = 0.5\n",
    "r_search = 2.0\n",
    "\n",
    "# definimos un ambiente discreto con las transiciones según el gráfico\n",
    "def generar_ambiente(alpha=alpha, beta=beta, r_wait=r_wait, r_search=r_search):\n",
    "    P[0][0] = [(1.0, 0, r_wait, False)]\n",
    "    P[0][1] = [(alpha, 0, r_search, False),\n",
    "               (1-alpha, 1, r_search, False)]\n",
    "    P[0][2] = [(1,0,0,False)]\n",
    "\n",
    "    P[1][0] = [(1.0, 1, r_wait, False)]\n",
    "    P[1][1] = [(beta, 1, r_search, False), \n",
    "               (1-beta, 0, -3.0, False)]\n",
    "    P[1][2] = [(1.0, 0, 0.0, False)]\n",
    "    env = discrete.DiscreteEnv(2, 3, P, [0.0, 1.0])\n",
    "    return(env)\n",
    "env = generar_ambiente()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvcF7--Z6aX8"
   },
   "source": [
    "# Implemente la estrategia random para veinte episodios. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoNiKgvOIC3n"
   },
   "source": [
    "Definir una acción aleatoria y ver que reward produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomExperiment(env):\n",
    "    print(\"Obs\\tDone\\tReward\\tC.Reward\\tAction\")\n",
    "    verbose=True\n",
    "    history = []\n",
    "    rewardAcum = 0\n",
    "    state=1 # < starting state\n",
    "    for i in range(50):\n",
    "        #action = env.action_space.sample()\n",
    "        if state == 1:\n",
    "            action = np.random.choice([0,1,2])\n",
    "        else:\n",
    "            action = np.random.choice([0,1])\n",
    "        state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            observation = env.reset()\n",
    "        rewardAcum += reward\n",
    "        elemHist = np.array([i, reward, rewardAcum])\n",
    "        history.append(elemHist)\n",
    "        if verbose:\n",
    "            print(state,\"\\t\", done,\"\\t\", reward, \"\\t\", \"%.4f\" % rewardAcum, \"\\t\", action)\n",
    "        env.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs\tDone\tReward\tC.Reward\tAction\n",
      "0 \t False \t 0.0 \t 0.0000 \t 2\n",
      "0 \t False \t 2.0 \t 2.0000 \t 1\n",
      "0 \t False \t 0.5 \t 2.5000 \t 0\n",
      "0 \t False \t 0.5 \t 3.0000 \t 0\n",
      "0 \t False \t 0.5 \t 3.5000 \t 0\n",
      "0 \t False \t 2.0 \t 5.5000 \t 1\n",
      "1 \t False \t 2.0 \t 7.5000 \t 1\n",
      "0 \t False \t -3.0 \t 4.5000 \t 1\n",
      "0 \t False \t 0.5 \t 5.0000 \t 0\n",
      "0 \t False \t 0.5 \t 5.5000 \t 0\n",
      "0 \t False \t 0.5 \t 6.0000 \t 0\n",
      "1 \t False \t 2.0 \t 8.0000 \t 1\n",
      "0 \t False \t -3.0 \t 5.0000 \t 1\n",
      "0 \t False \t 2.0 \t 7.0000 \t 1\n",
      "0 \t False \t 0.5 \t 7.5000 \t 0\n",
      "0 \t False \t 0.5 \t 8.0000 \t 0\n",
      "0 \t False \t 0.5 \t 8.5000 \t 0\n",
      "0 \t False \t 2.0 \t 10.5000 \t 1\n",
      "0 \t False \t 0.5 \t 11.0000 \t 0\n",
      "0 \t False \t 0.5 \t 11.5000 \t 0\n",
      "0 \t False \t 2.0 \t 13.5000 \t 1\n",
      "1 \t False \t 2.0 \t 15.5000 \t 1\n",
      "0 \t False \t 0.0 \t 15.5000 \t 2\n",
      "0 \t False \t 2.0 \t 17.5000 \t 1\n",
      "0 \t False \t 2.0 \t 19.5000 \t 1\n",
      "0 \t False \t 0.5 \t 20.0000 \t 0\n",
      "0 \t False \t 2.0 \t 22.0000 \t 1\n",
      "0 \t False \t 0.5 \t 22.5000 \t 0\n",
      "0 \t False \t 2.0 \t 24.5000 \t 1\n",
      "0 \t False \t 0.5 \t 25.0000 \t 0\n",
      "0 \t False \t 0.5 \t 25.5000 \t 0\n",
      "0 \t False \t 0.5 \t 26.0000 \t 0\n",
      "0 \t False \t 0.5 \t 26.5000 \t 0\n",
      "1 \t False \t 2.0 \t 28.5000 \t 1\n",
      "0 \t False \t 0.0 \t 28.5000 \t 2\n",
      "0 \t False \t 0.5 \t 29.0000 \t 0\n",
      "0 \t False \t 0.5 \t 29.5000 \t 0\n",
      "0 \t False \t 2.0 \t 31.5000 \t 1\n",
      "0 \t False \t 0.5 \t 32.0000 \t 0\n",
      "0 \t False \t 0.5 \t 32.5000 \t 0\n",
      "0 \t False \t 2.0 \t 34.5000 \t 1\n",
      "0 \t False \t 2.0 \t 36.5000 \t 1\n",
      "0 \t False \t 0.5 \t 37.0000 \t 0\n",
      "0 \t False \t 0.5 \t 37.5000 \t 0\n",
      "0 \t False \t 2.0 \t 39.5000 \t 1\n",
      "0 \t False \t 2.0 \t 41.5000 \t 1\n",
      "0 \t False \t 0.5 \t 42.0000 \t 0\n",
      "0 \t False \t 2.0 \t 44.0000 \t 1\n",
      "0 \t False \t 0.5 \t 44.5000 \t 0\n",
      "1 \t False \t 2.0 \t 46.5000 \t 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "env = generar_ambiente()\n",
    "data = randomExperiment(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9kpyAEk6aYB"
   },
   "source": [
    "# Grafique la recompensa acumulada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. ],\n",
       "       [1. , 2. , 2. ],\n",
       "       [2. , 0.5, 2.5],\n",
       "       [3. , 0.5, 3. ],\n",
       "       [4. , 0.5, 3.5],\n",
       "       [5. , 2. , 5.5]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history data to numpy,\n",
    "data = np.array(data)\n",
    "data[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 2. , 0.5, 0.5, 0.5, 2. ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so I can do this\n",
    "data[0:6, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bae1135128>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.xlabel(\"time step\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.xticks(np.arange(0,len(data),1))\n",
    "plt.plot(data[:,0], data[:,2], 'ro', label='Reward acumulado')\n",
    "plt.plot(data[:,0], data[:,1], 'b.', label='Reward instantaneo')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qC0PJOkV6aYH"
   },
   "source": [
    "# Calcule de forma teórica V, la value function optima para cada estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**PREGUNTAR v !!!**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #x: actual state\n",
    "    #y's: next states\n",
    "\n",
    "    V(x) = reward + gamma (sum_y( p(y|a,x) * V(y) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V^*(x) = R + \\gamma * \\sum_{y \\in S'}\\ p(y\\ |\\ a,x) * V(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRz0uMX1LbXz"
   },
   "source": [
    "# Implemente el algoritmo de iteración de valor (Value iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/value-iteration-4.4.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVuBLOrWL1ru"
   },
   "source": [
    "  Evaluate the optimal value function given a full description of the environment dynamics\n",
    "  \n",
    "  \n",
    "\n",
    "```\n",
    " Args:\n",
    "\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "  \n",
    "  Returns:\n",
    "        Vector of length env.nS representing the value function.\n",
    "```\n",
    "\n",
    "\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En cada estado, quiero calcular la value function optima;\n",
    "# uso ecuacion de bellman, tomando el reward instantaneo y\n",
    "# estimando futuros posibles rewards a partir de las acciones.\n",
    "def valueIteration(env, theta=0.1, gamma=0.9, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"epoch\\tvalue V\")\n",
    "    update=float('inf')\n",
    "    V = np.zeros(env.nS)\n",
    "    epoch=0\n",
    "    while(update > theta):\n",
    "        # bellman eq; for each state:\n",
    "        for s in range(env.nS):\n",
    "            vPrev = V[s]\n",
    "            maxReward = -float('inf')\n",
    "            for a in range(env.nA):\n",
    "                sumFutureRewards = 0\n",
    "                for prob, next_state, reward, done in env.P[s][a]:\n",
    "                    # sum rewards over all possible next states\n",
    "                    # (an action may result in many outcomes)\n",
    "                    sumFutureRewards += prob * (reward + gamma*V[next_state])\n",
    "                # selecting max reward from all possible actions 'a' at that state 's'\n",
    "                if(maxReward < sumFutureRewards):\n",
    "                    maxReward = sumFutureRewards\n",
    "            # updating value function\n",
    "            V[s] = maxReward\n",
    "            #we stop when update < theta\n",
    "            update = abs(V[s] - vPrev)\n",
    "        epoch += 1\n",
    "        if verbose:\n",
    "            print(epoch, \":\", V)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function optima:\n",
      "V = [state-1:    state-2:   ]\n",
      "V = [16.21487099 14.59338389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "def testValueIteration():\n",
    "    env = generar_ambiente()\n",
    "    print(\"Value function optima:\")\n",
    "    print(\"V = [state-1:    state-2:   ]\")\n",
    "    print(\"V =\", valueIteration(env))\n",
    "testValueIteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGWxWGNA6aYJ"
   },
   "source": [
    "# Implemente el algoritmo de policy iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9o3S2kaKQKX"
   },
   "source": [
    "Definir primero una funcion de evaluación de politica,\n",
    "\n",
    "```\n",
    "Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
    "    \n",
    "    Args:\n",
    "        policy: [S, A] shaped matrix representing the policy.\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "    \n",
    "    Returns:\n",
    "        Vector of length env.nS representing the value function.\n",
    "        \n",
    "```\n",
    "\n",
    "Despues una funcion de optimisacion de la politica:\n",
    "\n",
    "\n",
    "```\n",
    " Policy Improvement Algorithm. Iteratively evaluates and improves a policy\n",
    "    until an optimal policy is found.\n",
    "    \n",
    "    Args:\n",
    "        env: The OpenAI envrionment.\n",
    "        policy_eval_fn: Policy Evaluation function that takes 3 arguments:\n",
    "            policy, env, discount_factor.\n",
    "        discount_factor: gamma discount factor.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (policy, V). \n",
    "        policy is the optimal policy, a matrix of shape [S, A] where each state s\n",
    "        contains a valid probability distribution over actions.\n",
    "        V is the value function for the optimal policy.\n",
    "        \n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/policy-evaluation-4.1.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/value-vs-policy.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Evaluation \n",
    "# en cada estado, quiero calcular la value function PARA UNA POLICY PI;\n",
    "# uso ecuacion de bellman, tomando el reward instantaneo y\n",
    "# estimando futuros posibles rewards a partir de las acciones, que son elegidas\n",
    "# siguiendo la policy pi.\n",
    "def policyEvaluation(env, policy, theta=0.1, gamma=0.9, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"epoch\\tvalue V^pi_i\")\n",
    "    update=float('inf')\n",
    "    Vpi = np.zeros(env.nS)\n",
    "    epoch=0\n",
    "    while(update > theta):\n",
    "        # bellman eq; for each state:\n",
    "        for s in range(env.nS):\n",
    "            vPrev = Vpi[s]\n",
    "            piReward = -float('inf')\n",
    "            piReward = 0\n",
    "            # the policy is deterministic, so it always choose the same action\n",
    "            a = np.random.choice([0,1,2], p=policy[s])\n",
    "            for prob, next_state, reward, done in env.P[s][a]:\n",
    "                # sums possible rewards ONLY OVER policy's actions\n",
    "                piReward += prob * (reward + gamma*Vpi[next_state])\n",
    "            # this action at this state costs/reward us 'piReward'\n",
    "            Vpi[s] = piReward\n",
    "            update = abs(Vpi[s] - vPrev)\n",
    "        epoch += 1\n",
    "        if verbose:\n",
    "            print(epoch, \":\", Vpi)\n",
    "    return Vpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPoliEval():\n",
    "    env = generar_ambiente()\n",
    "    # discrete random policy\n",
    "    policy=np.zeros((env.nS, env.nA))#[S,A]\n",
    "    policy[0][np.random.choice([0,1])] = 1\n",
    "    policy[1][np.random.choice([0,1,2])] = 1\n",
    "    # run policy evaluation and returns its value \n",
    "    return policyEvaluation(env, policy, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tvalue V^pi_i\n",
      "1 : [2.  0.5]\n",
      "2 : [3.53 0.95]\n",
      "3 : [4.7126 1.355 ]\n",
      "4 : [5.636972 1.7195  ]\n",
      "5 : [6.36812984 2.04755   ]\n",
      "6 : [6.95361248 2.342795  ]\n",
      "7 : [7.42830409 2.6085155 ]\n",
      "8 : [7.81791173 2.84766395]\n",
      "9 : [8.14147596 3.06289756]\n",
      "10 : [8.41318425 3.2566078 ]\n",
      "11 : [8.64368206 3.43094702]\n",
      "12 : [8.84102155 3.58785232]\n",
      "13 : [9.01134893 3.72906709]\n",
      "14 : [9.15940331 3.85616038]\n",
      "15 : [9.28887925 3.97054434]\n",
      "16 : [9.40269104 4.07348991]\n",
      "17 : [9.50316573 4.16614092]\n",
      "[9.50316573 4.16614092]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "# Policy Evaluation test with random policy\n",
    "print(testPoliEval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/policy-iteration-4.3.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/value-iteration-4.4.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyImprovement(env, policy, gamma=0.9):\n",
    "    policyStable = False\n",
    "    theta=0.1\n",
    "    V = policyEvaluation(env, policy, gamma=0.9, verbose=False)\n",
    "    update=float('inf')\n",
    "    while(not policyStable):\n",
    "        policyStable = True\n",
    "        for s in range(env.nS):\n",
    "            vPrev = V\n",
    "            oldA = np.array(policy[s])\n",
    "            maxReward = -float('inf')\n",
    "            maxAction = 0;\n",
    "            for a in range(env.nA):\n",
    "                sumFutureRewards = 0\n",
    "                for prob, next_state, reward, done in env.P[s][a]:\n",
    "                    # we weight our future reward estimation with our\n",
    "                    # estimated value function\n",
    "                    sumFutureRewards += prob * (reward + gamma*V[next_state])\n",
    "                # me quedo con el mayor reward entre todas las actions 'a' posibles\n",
    "                # en el estado s\n",
    "                if(maxReward < sumFutureRewards):\n",
    "                    maxReward = sumFutureRewards\n",
    "                    maxAction = a\n",
    "            oneHot = np.zeros(3)\n",
    "            oneHot[maxAction] = 1\n",
    "            policy[s] = oneHot\n",
    "            if not np.array_equal(oldA, policy[s]):\n",
    "                policyStable = False\n",
    "        if policyStable:\n",
    "            return (policy, V)\n",
    "        else:\n",
    "            V = policyEvaluation(env, policy, gamma=0.9, verbose=False)\n",
    "            #como lo comparo? que mido?\n",
    "        #update = np.mean(abs(V[s] - vPrev))\n",
    "        #print(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPolicyImprovement():\n",
    "    env = generar_ambiente()\n",
    "    # discrete random policy\n",
    "    policy=np.zeros((env.nS, env.nA))#[S,A]\n",
    "    policy[0][np.random.choice([0,1])] = 1\n",
    "    policy[1][np.random.choice([0,1,2])] = 1\n",
    "    # run policy evaluation and returns its value\n",
    "    print(\"Policy to improve:\")\n",
    "    print(policy)\n",
    "    return policyImprovement(env, policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy to improve:\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "Optimal policy: \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 1.]] \n",
      "Value: \n",
      " [16.21487099 14.59338389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "policy, V = testPolicyImprovement()\n",
    "print(\"Optimal policy: \\n\",policy,\"\\nValue: \\n\",V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brOjUJvE6aYV"
   },
   "source": [
    "# Utilizando los 3 algoritmos, realice los experimentos para las siguientes configuraciones del ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVKvrm0t6aYV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "exp1 = generar_ambiente(alpha=0.9, beta=0.9, r_search=3, r_wait=2)\n",
    "exp2 = generar_ambiente(alpha=0.8, beta=0.5, r_search=3, r_wait=2)\n",
    "exp3 = generar_ambiente(alpha=0.5, beta=0.5, r_search=3, r_wait=2)\n",
    "exp4 = generar_ambiente(alpha=0.9, beta=0.6, r_search=1, r_wait=0.9)\n",
    "exp5 = generar_ambiente(alpha=0.9, beta=0.6, r_search=1, r_wait=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAT_YZq56aYY"
   },
   "source": [
    "# Utilizando el grafico de recompensa, compare las estrategias óptimas generadas con los experimentos anteriores contra la estrategia al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tvalue V\n",
      "1 : [3.  2.7]\n",
      "2 : [5.673  5.1057]\n",
      "3 : [8.054643   7.26053487]\n",
      "4 : [10.17770897  9.19702705]\n",
      "5 : [12.0716767  10.93604281]\n",
      "6 : [13.76230198 12.49680186]\n",
      "7 : [15.27217677 13.89690541]\n",
      "8 : [16.62118467 15.15240001]\n",
      "9 : [17.82687558 16.27786281]\n",
      "10 : [18.90477688 17.28649879]\n",
      "11 : [19.86865416 18.1902429 ]\n",
      "12 : [20.73073173 18.9998626 ]\n",
      "13 : [21.50188034 19.72505794]\n",
      "14 : [22.19177829 20.37455698]\n",
      "15 : [22.80905054 20.9562057 ]\n",
      "16 : [23.36138945 21.47705167]\n",
      "17 : [23.8556601  21.94342126]\n",
      "18 : [24.2979926  22.36099055]\n",
      "19 : [24.69386315 22.73485003]\n",
      "20 : [25.04816566 23.06956344]\n",
      "21 : [25.36527489 23.36922112]\n",
      "22 : [25.64910256 23.63748834]\n",
      "23 : [25.90314703 23.87764879]\n",
      "24 : [26.13053748 24.09264389]\n",
      "25 : [26.33407331 24.28510815]\n",
      "26 : [26.51625912 24.45740092]\n",
      "27 : [26.67933597 24.61163498]\n",
      "28 : [26.82530928 24.74970217]\n",
      "29 : [26.95597371 24.87329639]\n",
      "30 : [27.07293538 24.98393426]\n",
      "31 : [27.17763174 25.08297361]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.17763174, 25.08297361])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = generar_ambiente(alpha=0.9, beta=0.9, r_search=3, r_wait=2)\n",
    "valueIteration(env=exp3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tvalue V\n",
      "1 : [3.  2.7]\n",
      "2 : [5.673  5.1057]\n",
      "3 : [8.054643   7.26053487]\n",
      "4 : [10.17770897  9.19702705]\n",
      "5 : [12.0716767  10.93604281]\n",
      "6 : [13.76230198 12.49680186]\n",
      "7 : [15.27217677 13.89690541]\n",
      "8 : [16.62118467 15.15240001]\n",
      "9 : [17.82687558 16.27786281]\n",
      "10 : [18.90477688 17.28649879]\n",
      "11 : [19.86865416 18.1902429 ]\n",
      "12 : [20.73073173 18.9998626 ]\n",
      "13 : [21.50188034 19.72505794]\n",
      "14 : [22.19177829 20.37455698]\n",
      "15 : [22.80905054 20.9562057 ]\n",
      "16 : [23.36138945 21.47705167]\n",
      "17 : [23.8556601  21.94342126]\n",
      "18 : [24.2979926  22.36099055]\n",
      "19 : [24.69386315 22.73485003]\n",
      "20 : [25.04816566 23.06956344]\n",
      "21 : [25.36527489 23.36922112]\n",
      "22 : [25.64910256 23.63748834]\n",
      "23 : [25.90314703 23.87764879]\n",
      "24 : [26.13053748 24.09264389]\n",
      "25 : [26.33407331 24.28510815]\n",
      "26 : [26.51625912 24.45740092]\n",
      "27 : [26.67933597 24.61163498]\n",
      "28 : [26.82530928 24.74970217]\n",
      "29 : [26.95597371 24.87329639]\n",
      "30 : [27.07293538 24.98393426]\n",
      "31 : [27.17763174 25.08297361]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.17763174, 25.08297361])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueIteration(exp1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tvalue V\n",
      "1 : [3.  2.7]\n",
      "2 : [5.673  5.1057]\n",
      "3 : [8.054643   7.26053487]\n",
      "4 : [10.17770897  9.19702705]\n",
      "5 : [12.0716767  10.93604281]\n",
      "6 : [13.76230198 12.49680186]\n",
      "7 : [15.27217677 13.89690541]\n",
      "8 : [16.62118467 15.15240001]\n",
      "9 : [17.82687558 16.27786281]\n",
      "10 : [18.90477688 17.28649879]\n",
      "11 : [19.86865416 18.1902429 ]\n",
      "12 : [20.73073173 18.9998626 ]\n",
      "13 : [21.50188034 19.72505794]\n",
      "14 : [22.19177829 20.37455698]\n",
      "15 : [22.80905054 20.9562057 ]\n",
      "16 : [23.36138945 21.47705167]\n",
      "17 : [23.8556601  21.94342126]\n",
      "18 : [24.2979926  22.36099055]\n",
      "19 : [24.69386315 22.73485003]\n",
      "20 : [25.04816566 23.06956344]\n",
      "21 : [25.36527489 23.36922112]\n",
      "22 : [25.64910256 23.63748834]\n",
      "23 : [25.90314703 23.87764879]\n",
      "24 : [26.13053748 24.09264389]\n",
      "25 : [26.33407331 24.28510815]\n",
      "26 : [26.51625912 24.45740092]\n",
      "27 : [26.67933597 24.61163498]\n",
      "28 : [26.82530928 24.74970217]\n",
      "29 : [26.95597371 24.87329639]\n",
      "30 : [27.07293538 24.98393426]\n",
      "31 : [27.17763174 25.08297361]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.17763174, 25.08297361])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueIteration(exp2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tvalue V\n",
      "1 : [3.  2.7]\n",
      "2 : [5.673  5.1057]\n",
      "3 : [8.054643   7.26053487]\n",
      "4 : [10.17770897  9.19702705]\n",
      "5 : [12.0716767  10.93604281]\n",
      "6 : [13.76230198 12.49680186]\n",
      "7 : [15.27217677 13.89690541]\n",
      "8 : [16.62118467 15.15240001]\n",
      "9 : [17.82687558 16.27786281]\n",
      "10 : [18.90477688 17.28649879]\n",
      "11 : [19.86865416 18.1902429 ]\n",
      "12 : [20.73073173 18.9998626 ]\n",
      "13 : [21.50188034 19.72505794]\n",
      "14 : [22.19177829 20.37455698]\n",
      "15 : [22.80905054 20.9562057 ]\n",
      "16 : [23.36138945 21.47705167]\n",
      "17 : [23.8556601  21.94342126]\n",
      "18 : [24.2979926  22.36099055]\n",
      "19 : [24.69386315 22.73485003]\n",
      "20 : [25.04816566 23.06956344]\n",
      "21 : [25.36527489 23.36922112]\n",
      "22 : [25.64910256 23.63748834]\n",
      "23 : [25.90314703 23.87764879]\n",
      "24 : [26.13053748 24.09264389]\n",
      "25 : [26.33407331 24.28510815]\n",
      "26 : [26.51625912 24.45740092]\n",
      "27 : [26.67933597 24.61163498]\n",
      "28 : [26.82530928 24.74970217]\n",
      "29 : [26.95597371 24.87329639]\n",
      "30 : [27.07293538 24.98393426]\n",
      "31 : [27.17763174 25.08297361]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.17763174, 25.08297361])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueIteration(exp3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tvalue V\n",
      "1 : [3.  2.7]\n",
      "2 : [5.673  5.1057]\n",
      "3 : [8.054643   7.26053487]\n",
      "4 : [10.17770897  9.19702705]\n",
      "5 : [12.0716767  10.93604281]\n",
      "6 : [13.76230198 12.49680186]\n",
      "7 : [15.27217677 13.89690541]\n",
      "8 : [16.62118467 15.15240001]\n",
      "9 : [17.82687558 16.27786281]\n",
      "10 : [18.90477688 17.28649879]\n",
      "11 : [19.86865416 18.1902429 ]\n",
      "12 : [20.73073173 18.9998626 ]\n",
      "13 : [21.50188034 19.72505794]\n",
      "14 : [22.19177829 20.37455698]\n",
      "15 : [22.80905054 20.9562057 ]\n",
      "16 : [23.36138945 21.47705167]\n",
      "17 : [23.8556601  21.94342126]\n",
      "18 : [24.2979926  22.36099055]\n",
      "19 : [24.69386315 22.73485003]\n",
      "20 : [25.04816566 23.06956344]\n",
      "21 : [25.36527489 23.36922112]\n",
      "22 : [25.64910256 23.63748834]\n",
      "23 : [25.90314703 23.87764879]\n",
      "24 : [26.13053748 24.09264389]\n",
      "25 : [26.33407331 24.28510815]\n",
      "26 : [26.51625912 24.45740092]\n",
      "27 : [26.67933597 24.61163498]\n",
      "28 : [26.82530928 24.74970217]\n",
      "29 : [26.95597371 24.87329639]\n",
      "30 : [27.07293538 24.98393426]\n",
      "31 : [27.17763174 25.08297361]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.17763174, 25.08297361])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueIteration(exp4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tvalue V\n",
      "1 : [3.  2.7]\n",
      "2 : [5.673  5.1057]\n",
      "3 : [8.054643   7.26053487]\n",
      "4 : [10.17770897  9.19702705]\n",
      "5 : [12.0716767  10.93604281]\n",
      "6 : [13.76230198 12.49680186]\n",
      "7 : [15.27217677 13.89690541]\n",
      "8 : [16.62118467 15.15240001]\n",
      "9 : [17.82687558 16.27786281]\n",
      "10 : [18.90477688 17.28649879]\n",
      "11 : [19.86865416 18.1902429 ]\n",
      "12 : [20.73073173 18.9998626 ]\n",
      "13 : [21.50188034 19.72505794]\n",
      "14 : [22.19177829 20.37455698]\n",
      "15 : [22.80905054 20.9562057 ]\n",
      "16 : [23.36138945 21.47705167]\n",
      "17 : [23.8556601  21.94342126]\n",
      "18 : [24.2979926  22.36099055]\n",
      "19 : [24.69386315 22.73485003]\n",
      "20 : [25.04816566 23.06956344]\n",
      "21 : [25.36527489 23.36922112]\n",
      "22 : [25.64910256 23.63748834]\n",
      "23 : [25.90314703 23.87764879]\n",
      "24 : [26.13053748 24.09264389]\n",
      "25 : [26.33407331 24.28510815]\n",
      "26 : [26.51625912 24.45740092]\n",
      "27 : [26.67933597 24.61163498]\n",
      "28 : [26.82530928 24.74970217]\n",
      "29 : [26.95597371 24.87329639]\n",
      "30 : [27.07293538 24.98393426]\n",
      "31 : [27.17763174 25.08297361]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.17763174, 25.08297361])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueIteration(exp5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.17763174, 25.08297361])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueIteration(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jack\\gym\\gym\\__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24.66801105, 22.20120994])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gym import spaces\n",
    "exp2 = generar_ambiente(alpha=0.8, beta=0.5, r_search=3, r_wait=2)\n",
    "valueIteration(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP1 - (Sin solucion).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
